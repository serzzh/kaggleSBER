{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filenames):\n",
    "    arrays = [0,0,0]\n",
    "    for i in xrange(len(filenames)):\n",
    "        arrays[i] = pd.read_csv(filenames[i])\n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def yes_1(x):\n",
    "    return x.replace('yes', 1).replace('no',-1).replace(\"excellent\",2).replace(\"good\",1).replace(\n",
    "        \"satisfactory\",0).replace(\"poor\",-1).replace(\"no data\",0).replace(\"Investment\", 1).replace(\"OwnerOccupier\",-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_impute(data):\n",
    "    data[\"life_sq\"]=data[\"life_sq\"]/data[\"full_sq\"]\n",
    "    data[\"max_floor\"]=data[\"max_floor\"]/data[\"floor\"]\n",
    "    data[\"num_room\"]=data[\"num_room\"]/data[\"full_sq\"]\n",
    "    data['green_part_2000']=data['green_part_2000'].fillna(data['green_part_1500'])\n",
    "    data['prom_part_5000']=data['prom_part_5000'].fillna(data['prom_part_2000'])\n",
    "    data=data.apply(yes_1)\n",
    "    medImputer=Imputer(strategy='median')\n",
    "    mfImputer=Imputer(strategy='most_frequent')\n",
    "    data[[\"material\",\"build_year\",\"state\",\"product_type\"]]=mfImputer.fit_transform(data[[\"material\",\"build_year\",\"state\",\"product_type\"]])\n",
    "    data[[\"life_sq\",\"max_floor\",\"num_room\",\"kitch_sq\"]]=medImputer.fit_transform(data[[\"life_sq\",\"max_floor\",\"num_room\",\"kitch_sq\"]])\n",
    "    data[\"build_year\"]=2017-data[\"build_year\"]\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_transport(data):\n",
    "    data[\"metro_km_walk\"]=data[\"metro_km_walk\"].fillna(data[\"metro_km_avto\"])\n",
    "    data[\"metro_min_walk\"]=data[\"metro_min_walk\"].fillna(data[\"metro_km_avto\"]*12)\n",
    "    data[\"railroad_station_walk_km\"]=data[\"railroad_station_walk_km\"].fillna(data[\"railroad_station_avto_km\"])\n",
    "    data[\"railroad_station_walk_min\"]=data[\"railroad_station_walk_min\"].fillna(data[\"railroad_station_avto_km\"]*12)\n",
    "    data[\"ID_railroad_station_walk\"]=data[\"ID_railroad_station_walk\"].fillna(data[\"ID_railroad_station_avto\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_cafe(data):\n",
    "    st0=['cafe_sum_5000_min_price_avg','cafe_sum_5000_max_price_avg','cafe_avg_price_5000']\n",
    "    l=['5000','3000','2000','1500','1000','500']\n",
    "    medImputer=Imputer(strategy='median')\n",
    "    data[st0]=medImputer.fit_transform(data[st0])\n",
    "    for i in xrange(len(l)-1):\n",
    "        st1=[st.replace('5000',str(l[i+1])) for st in st0]\n",
    "        st2=[st.replace('5000',str(l[i])) for st in st0]\n",
    "        for k in xrange(len(st1)):\n",
    "            data[st1[k]]=data[st1[k]].fillna(data[st2[k]])\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rm_col(data, thrs):\n",
    "    k=len(data)-data.count()\n",
    "    return list(k[k<thrs].index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "def data_transform(data, macro, div):\n",
    "    data[\"timestamp\"]=pd.to_datetime(data[\"timestamp\"],format='%Y-%m-%d')\n",
    "    macro[\"timestamp\"]=pd.to_datetime(macro[\"timestamp\"],format='%Y-%m-%d')\n",
    "    data = data.merge(macro, left_on='timestamp', right_on='timestamp', how='left')   \n",
    "    data=my_impute(data)\n",
    "    data=data.ix[data['floor']>0]\n",
    "    data=data.ix[data['full_sq']>0]\n",
    "    data=my_transport(data)\n",
    "    data=my_cafe(data)\n",
    "    data1 = data[data[div[0]].isin(div[1])]\n",
    "    data2 = data[-data[div[0]].isin(div[1])]\n",
    "    data1=data1[rm_col(data1,650)]\n",
    "    data2=data2[rm_col(data2,1800)]\n",
    "    return data1, data2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printna(data):\n",
    "    k=len(data)-data.count()\n",
    "    print k[k>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def er10(data):\n",
    "    err = (data.full_sq>data.life_sq*10)&(data.life_sq>2)\n",
    "    data.ix[err,'full_sq'] = data.ix[err,'full_sq']/10\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def excl_cheat(data, quan = .05):\n",
    "    data = data[data[\"price_doc\"]>2000000]\n",
    "    df = data.groupby(\"sub_area\")\n",
    "    result = pd.DataFrame()\n",
    "    for name, group in df:\n",
    "        q = group.pr_RUB_SQM.quantile(quan)\n",
    "        group = group[group.pr_RUB_SQM > q]\n",
    "        result = result.append(group)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = [\"./data/macro.csv\",\"./data/train.csv/train.csv\",\"./data/test.csv/test.csv\"]\n",
    "[macro, data, data_test] = read_data(filenames)\n",
    "data=er10(er10(data))\n",
    "data[\"pr_RUB_SQM\"] = data[\"price_doc\"]/data[\"full_sq\"]\n",
    "#data = excl_cheat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test[\"full_sq\"]=data_test[\"full_sq\"].fillna(data_test[\"life_sq\"])\n",
    "data_test.ix[data_test[\"full_sq\"]==0,'full_sq'] = data_test.ix[data_test[\"full_sq\"]==0,'life_sq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "div=['sub_area',data[data.preschool_quota.isnull()]['sub_area'].value_counts().index.tolist()]\n",
    "[data1, data2]=data_transform(data, macro, div)\n",
    "[data_test1, data_test2]=data_transform(data_test, macro, div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test2=data_test2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "printna(data_test1)\n",
    "printna(data_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model(dim, reg=0.01):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dim, input_dim=dim, kernel_initializer='random_normal', activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(reg),activity_regularizer=regularizers.l1(reg)))\n",
    "    model.add(Dense(148, kernel_initializer='random_normal', activation='relu',\n",
    "                   kernel_regularizer=regularizers.l2(reg),activity_regularizer=regularizers.l1(reg)))\n",
    "    model.add(Dense(20, kernel_initializer='random_normal', activation='relu',\n",
    "                   kernel_regularizer=regularizers.l2(reg),activity_regularizer=regularizers.l1(reg)))\n",
    "    model.add(Dense(1, kernel_initializer='random_normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NN1=load_model('nn1.h5')\n",
    "#NN2=load_model('nn2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex=[\"id\",\"timestamp\",\"sub_area\", \"ID_metro\", \"ID_railroad_station_walk\", \"ID_railroad_station_avto\", \n",
    "    \"ID_big_road1\", \"ID_big_road2\", \"ID_railroad_terminal\", \"ID_bus_terminal\", 'hospital_beds_raion']\n",
    "v1=[x for x in list(data_test1.columns.values) if x not in ex]\n",
    "v=[x for x in list(data_test2.columns.values) if x not in ex]\n",
    "Y2, X2, X2_test = map(np.array, [data2[\"price_doc\"], data2[v1], data_test2[v1]])\n",
    "batch_size2=X2.shape[0]/50 \n",
    "#x_train, x_test = labels(x_train), labels(x_test||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN2 = larger_model(dim=X2.shape[1], reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23692/23692 [==============================] - 0s - loss: 45965199494504.8125     \n",
      "Epoch 2/200\n",
      "23692/23692 [==============================] - 0s - loss: 25628902796968.3008     \n",
      "Epoch 3/200\n",
      "23692/23692 [==============================] - 0s - loss: 25096957714126.3398     \n",
      "Epoch 4/200\n",
      "23692/23692 [==============================] - 0s - loss: 24833650304404.7266     \n",
      "Epoch 5/200\n",
      "23692/23692 [==============================] - 0s - loss: 24615977878544.0781     \n",
      "Epoch 6/200\n",
      "23692/23692 [==============================] - 0s - loss: 24332367823334.8477     \n",
      "Epoch 7/200\n",
      "23692/23692 [==============================] - 0s - loss: 24260114682346.3047     \n",
      "Epoch 8/200\n",
      "23692/23692 [==============================] - 0s - loss: 24109604512619.4922     \n",
      "Epoch 9/200\n",
      "23692/23692 [==============================] - 0s - loss: 24035936482739.8438     \n",
      "Epoch 10/200\n",
      "23692/23692 [==============================] - 0s - loss: 23911559606287.9023     \n",
      "Epoch 11/200\n",
      "23692/23692 [==============================] - 0s - loss: 23893051982081.2539     \n",
      "Epoch 12/200\n",
      "23692/23692 [==============================] - 0s - loss: 23817491703468.1094     \n",
      "Epoch 13/200\n",
      "23692/23692 [==============================] - 0s - loss: 23750675960408.9492     \n",
      "Epoch 14/200\n",
      "23692/23692 [==============================] - 0s - loss: 23685794272939.4141     \n",
      "Epoch 15/200\n",
      "23692/23692 [==============================] - 0s - loss: 23697028935416.5234     \n",
      "Epoch 16/200\n",
      "23692/23692 [==============================] - 0s - loss: 23626313628545.2773     \n",
      "Epoch 17/200\n",
      "23692/23692 [==============================] - 0s - loss: 23693162128229.9609     \n",
      "Epoch 18/200\n",
      "23692/23692 [==============================] - 0s - loss: 23632960581506.8320     \n",
      "Epoch 19/200\n",
      "23692/23692 [==============================] - 0s - loss: 23693315361422.5469     \n",
      "Epoch 20/200\n",
      "23692/23692 [==============================] - 0s - loss: 23530191389059.2617     \n",
      "Epoch 21/200\n",
      "23692/23692 [==============================] - 0s - loss: 23560383202026.8633     \n",
      "Epoch 22/200\n",
      "23692/23692 [==============================] - 0s - loss: 23555788142078.5312     \n",
      "Epoch 23/200\n",
      "23692/23692 [==============================] - 0s - loss: 23604008610165.7773     \n",
      "Epoch 24/200\n",
      "23692/23692 [==============================] - 0s - loss: 23740729135765.8047     \n",
      "Epoch 25/200\n",
      "23692/23692 [==============================] - 0s - loss: 23368873114049.1562     \n",
      "Epoch 26/200\n",
      "23692/23692 [==============================] - 0s - loss: 23294235465296.1328     \n",
      "Epoch 27/200\n",
      "23692/23692 [==============================] - 0s - loss: 23347360726403.7812     \n",
      "Epoch 28/200\n",
      "23692/23692 [==============================] - 0s - loss: 23266291241215.1758     \n",
      "Epoch 29/200\n",
      "23692/23692 [==============================] - 0s - loss: 23235433096217.7617     \n",
      "Epoch 30/200\n",
      "23692/23692 [==============================] - 0s - loss: 23325054496841.9961     \n",
      "Epoch 31/200\n",
      "23692/23692 [==============================] - 0s - loss: 23203614928950.6328     \n",
      "Epoch 32/200\n",
      "23692/23692 [==============================] - 0s - loss: 23249701884563.0391     \n",
      "Epoch 33/200\n",
      "23692/23692 [==============================] - 0s - loss: 23049319023753.7891     \n",
      "Epoch 34/200\n",
      "23692/23692 [==============================] - 0s - loss: 23126527677072.2734     \n",
      "Epoch 35/200\n",
      "23692/23692 [==============================] - 0s - loss: 23050934026948.1406     \n",
      "Epoch 36/200\n",
      "23692/23692 [==============================] - 0s - loss: 23232367631284.4492     \n",
      "Epoch 37/200\n",
      "23692/23692 [==============================] - 0s - loss: 23112344971142.6328     \n",
      "Epoch 38/200\n",
      "23692/23692 [==============================] - 0s - loss: 22979214341785.4375     \n",
      "Epoch 39/200\n",
      "23692/23692 [==============================] - 0s - loss: 22850979088358.0664     \n",
      "Epoch 40/200\n",
      "23692/23692 [==============================] - 0s - loss: 22883116324130.6211     \n",
      "Epoch 41/200\n",
      "23692/23692 [==============================] - 0s - loss: 22821830427758.1289     \n",
      "Epoch 42/200\n",
      "23692/23692 [==============================] - 0s - loss: 22980132398398.9727     \n",
      "Epoch 43/200\n",
      "23692/23692 [==============================] - 0s - loss: 22694440680213.3945     \n",
      "Epoch 44/200\n",
      "23692/23692 [==============================] - 0s - loss: 22746096328110.6602     \n",
      "Epoch 45/200\n",
      "23692/23692 [==============================] - 0s - loss: 22709054308523.5039     \n",
      "Epoch 46/200\n",
      "23692/23692 [==============================] - 0s - loss: 22625788994013.1641     \n",
      "Epoch 47/200\n",
      "23692/23692 [==============================] - 0s - loss: 22655253488253.6016     \n",
      "Epoch 48/200\n",
      "23692/23692 [==============================] - 0s - loss: 22554311225628.2266     \n",
      "Epoch 49/200\n",
      "23692/23692 [==============================] - 0s - loss: 22674433680976.8242     \n",
      "Epoch 50/200\n",
      "23692/23692 [==============================] - 0s - loss: 22496431964049.3516     \n",
      "Epoch 51/200\n",
      "23692/23692 [==============================] - 0s - loss: 22542926882998.9141     \n",
      "Epoch 52/200\n",
      "23692/23692 [==============================] - 0s - loss: 22814279327703.8906     \n",
      "Epoch 53/200\n",
      "23692/23692 [==============================] - 0s - loss: 22459839067195.6445     \n",
      "Epoch 54/200\n",
      "23692/23692 [==============================] - 0s - loss: 22336667520358.0469     \n",
      "Epoch 55/200\n",
      "23692/23692 [==============================] - 0s - loss: 22298444203693.4922     \n",
      "Epoch 56/200\n",
      "23692/23692 [==============================] - 0s - loss: 22208017943049.7656     \n",
      "Epoch 57/200\n",
      "23692/23692 [==============================] - 0s - loss: 22449796880513.6641     \n",
      "Epoch 58/200\n",
      "23692/23692 [==============================] - 0s - loss: 22222864241354.3633     \n",
      "Epoch 59/200\n",
      "23692/23692 [==============================] - 0s - loss: 22059639409717.7656     \n",
      "Epoch 60/200\n",
      "23692/23692 [==============================] - 0s - loss: 22650945564812.3828     \n",
      "Epoch 61/200\n",
      "23692/23692 [==============================] - 0s - loss: 22086968933514.8281     \n",
      "Epoch 62/200\n",
      "23692/23692 [==============================] - 0s - loss: 22311758433986.5820     \n",
      "Epoch 63/200\n",
      "23692/23692 [==============================] - 0s - loss: 22068052080970.2109     \n",
      "Epoch 64/200\n",
      "23692/23692 [==============================] - 0s - loss: 21930163684199.3438     \n",
      "Epoch 65/200\n",
      "23692/23692 [==============================] - 0s - loss: 22064129443573.4102     \n",
      "Epoch 66/200\n",
      "23692/23692 [==============================] - 0s - loss: 22350189791457.7891     \n",
      "Epoch 67/200\n",
      "23692/23692 [==============================] - 0s - loss: 22057067811511.0000     \n",
      "Epoch 68/200\n",
      "23692/23692 [==============================] - 0s - loss: 21902965136759.3320     \n",
      "Epoch 69/200\n",
      "23692/23692 [==============================] - 0s - loss: 22150677199158.8477     \n",
      "Epoch 70/200\n",
      "23692/23692 [==============================] - 0s - loss: 21906734274703.4961     \n",
      "Epoch 71/200\n",
      "23692/23692 [==============================] - 0s - loss: 21793907203137.5234     \n",
      "Epoch 72/200\n",
      "23692/23692 [==============================] - 0s - loss: 21769531201129.0273     \n",
      "Epoch 73/200\n",
      "23692/23692 [==============================] - 0s - loss: 21794045093669.8203     \n",
      "Epoch 74/200\n",
      "23692/23692 [==============================] - 0s - loss: 21864979118039.5430     \n",
      "Epoch 75/200\n",
      "23692/23692 [==============================] - 0s - loss: 21872182813207.2539     \n",
      "Epoch 76/200\n",
      "23692/23692 [==============================] - 0s - loss: 21624522505548.4570     \n",
      "Epoch 77/200\n",
      "23692/23692 [==============================] - 0s - loss: 21652084121410.5195     \n",
      "Epoch 78/200\n",
      "23692/23692 [==============================] - 0s - loss: 21701325520613.8516     \n",
      "Epoch 79/200\n",
      "23692/23692 [==============================] - 0s - loss: 21570412206162.6367     \n",
      "Epoch 80/200\n",
      "23692/23692 [==============================] - 0s - loss: 21659332674891.4180     \n",
      "Epoch 81/200\n",
      "23692/23692 [==============================] - 0s - loss: 21842411963626.6055     \n",
      "Epoch 82/200\n",
      "23692/23692 [==============================] - 0s - loss: 21472785958164.0977     \n",
      "Epoch 83/200\n",
      "23692/23692 [==============================] - 0s - loss: 21572712144537.7812     \n",
      "Epoch 84/200\n",
      "23692/23692 [==============================] - 0s - loss: 21488782102019.7148     \n",
      "Epoch 85/200\n",
      "23692/23692 [==============================] - 0s - loss: 21416982040001.3281     \n",
      "Epoch 86/200\n",
      "23692/23692 [==============================] - 0s - loss: 21424009712797.8438     \n",
      "Epoch 87/200\n",
      "23692/23692 [==============================] - 0s - loss: 21366264270973.1680     \n",
      "Epoch 88/200\n",
      "23692/23692 [==============================] - 0s - loss: 21415391319184.0156     \n",
      "Epoch 89/200\n",
      "23692/23692 [==============================] - 0s - loss: 21266034790807.3164     \n",
      "Epoch 90/200\n",
      "23692/23692 [==============================] - 0s - loss: 21716611501502.5625     \n",
      "Epoch 91/200\n",
      "23692/23692 [==============================] - 0s - loss: 21468013081554.5312     \n",
      "Epoch 92/200\n",
      "23692/23692 [==============================] - 0s - loss: 21286097088574.9297     \n",
      "Epoch 93/200\n",
      "23692/23692 [==============================] - 0s - loss: 21291297307880.8789     \n",
      "Epoch 94/200\n",
      "23692/23692 [==============================] - 0s - loss: 21349373048667.0664     \n",
      "Epoch 95/200\n",
      "23692/23692 [==============================] - 0s - loss: 21364259142227.7617     \n",
      "Epoch 96/200\n",
      "23692/23692 [==============================] - 0s - loss: 21128648160401.3945     \n",
      "Epoch 97/200\n",
      "23692/23692 [==============================] - 0s - loss: 21018034955417.0039     \n",
      "Epoch 98/200\n",
      "23692/23692 [==============================] - 0s - loss: 21183763991459.1602     \n",
      "Epoch 99/200\n",
      "23692/23692 [==============================] - 0s - loss: 21037213637835.8320     \n",
      "Epoch 100/200\n",
      "23692/23692 [==============================] - 0s - loss: 21017666431275.0898     \n",
      "Epoch 101/200\n",
      "23692/23692 [==============================] - 0s - loss: 21070686376926.9766     \n",
      "Epoch 102/200\n",
      "23692/23692 [==============================] - 0s - loss: 20887997675095.0469     \n",
      "Epoch 103/200\n",
      "23692/23692 [==============================] - 0s - loss: 21034403316090.9648     \n",
      "Epoch 104/200\n",
      "23692/23692 [==============================] - 0s - loss: 21015075750463.3633     \n",
      "Epoch 105/200\n",
      "23692/23692 [==============================] - 0s - loss: 20805617574135.5703     \n",
      "Epoch 106/200\n",
      "23692/23692 [==============================] - 0s - loss: 20866425556503.0781     \n",
      "Epoch 107/200\n",
      "23692/23692 [==============================] - 0s - loss: 20893090697244.3555     \n",
      "Epoch 108/200\n",
      "23692/23692 [==============================] - 0s - loss: 20835098221146.6797     \n",
      "Epoch 109/200\n",
      "23692/23692 [==============================] - 0s - loss: 20832389304096.6328     \n",
      "Epoch 110/200\n",
      "23692/23692 [==============================] - 0s - loss: 20856048267822.0742     \n",
      "Epoch 111/200\n",
      "23692/23692 [==============================] - 0s - loss: 20981899081643.2852     \n",
      "Epoch 112/200\n",
      "23692/23692 [==============================] - 0s - loss: 21360620021998.2344     \n",
      "Epoch 113/200\n",
      "23692/23692 [==============================] - 0s - loss: 20885115985453.9023     \n",
      "Epoch 114/200\n",
      "23692/23692 [==============================] - 0s - loss: 21236521049255.8711     \n",
      "Epoch 115/200\n",
      "23692/23692 [==============================] - 0s - loss: 20807522528111.9844     \n",
      "Epoch 116/200\n",
      "23692/23692 [==============================] - 0s - loss: 20546738074965.7930     \n",
      "Epoch 117/200\n",
      "23692/23692 [==============================] - 0s - loss: 20527734510116.3945     \n",
      "Epoch 118/200\n",
      "23692/23692 [==============================] - 0s - loss: 20860239631808.2930     \n",
      "Epoch 119/200\n",
      "23692/23692 [==============================] - 0s - loss: 20693520399186.2500     \n",
      "Epoch 120/200\n",
      "23692/23692 [==============================] - 0s - loss: 20506578318630.7695     \n",
      "Epoch 121/200\n",
      "23692/23692 [==============================] - 0s - loss: 20512238054239.3906     \n",
      "Epoch 122/200\n",
      "23692/23692 [==============================] - 0s - loss: 20659562419003.7734     \n",
      "Epoch 123/200\n",
      "23692/23692 [==============================] - 0s - loss: 20583980908408.4570     \n",
      "Epoch 124/200\n",
      "23692/23692 [==============================] - 0s - loss: 20662056327740.2500     \n",
      "Epoch 125/200\n",
      "23692/23692 [==============================] - 0s - loss: 20461660634842.7891     \n",
      "Epoch 126/200\n",
      "23692/23692 [==============================] - 0s - loss: 20759169615209.8477     \n",
      "Epoch 127/200\n",
      "23692/23692 [==============================] - 0s - loss: 20585410240269.9609     \n",
      "Epoch 128/200\n",
      "23692/23692 [==============================] - 0s - loss: 20391679552907.3867     \n",
      "Epoch 129/200\n",
      "23692/23692 [==============================] - 0s - loss: 20512687642087.0195     \n",
      "Epoch 130/200\n",
      "23692/23692 [==============================] - 0s - loss: 20179068773573.2617     \n",
      "Epoch 131/200\n",
      "23692/23692 [==============================] - 0s - loss: 20358358848816.4531     \n",
      "Epoch 132/200\n",
      "23692/23692 [==============================] - 0s - loss: 20318309780185.2305     \n",
      "Epoch 133/200\n",
      "23692/23692 [==============================] - 0s - loss: 20211757980956.0508     \n",
      "Epoch 134/200\n",
      "23692/23692 [==============================] - 0s - loss: 20396244388843.0820     \n",
      "Epoch 135/200\n",
      "23692/23692 [==============================] - 0s - loss: 20424708277532.3984     \n",
      "Epoch 136/200\n",
      "23692/23692 [==============================] - 0s - loss: 20310868716126.1367     \n",
      "Epoch 137/200\n",
      "23692/23692 [==============================] - 0s - loss: 20443822607671.0195     \n",
      "Epoch 138/200\n",
      "23692/23692 [==============================] - 0s - loss: 20243793823430.3867     \n",
      "Epoch 139/200\n",
      "23692/23692 [==============================] - 0s - loss: 20207931650785.8750     \n",
      "Epoch 140/200\n",
      "23692/23692 [==============================] - 0s - loss: 21208034226308.0859     \n",
      "Epoch 141/200\n",
      "23692/23692 [==============================] - 0s - loss: 20361583094808.7227     \n",
      "Epoch 142/200\n",
      "23692/23692 [==============================] - 0s - loss: 20433535272444.4570     \n",
      "Epoch 143/200\n",
      "23692/23692 [==============================] - 0s - loss: 20195125304023.1562     \n",
      "Epoch 144/200\n",
      "23692/23692 [==============================] - 0s - loss: 20338304873888.4805     \n",
      "Epoch 145/200\n",
      "23692/23692 [==============================] - 0s - loss: 20333438369648.1602     \n",
      "Epoch 146/200\n",
      "23692/23692 [==============================] - 0s - loss: 20135045994653.3242     \n",
      "Epoch 147/200\n",
      "23692/23692 [==============================] - 0s - loss: 20046098663754.9023     \n",
      "Epoch 148/200\n",
      "23692/23692 [==============================] - 0s - loss: 20318820275241.6641     \n",
      "Epoch 149/200\n",
      "23692/23692 [==============================] - 0s - loss: 19967066127070.0703     \n",
      "Epoch 150/200\n",
      "23692/23692 [==============================] - 0s - loss: 19933364674818.6367     \n",
      "Epoch 151/200\n",
      "23692/23692 [==============================] - 0s - loss: 20068888442952.9570     \n",
      "Epoch 152/200\n",
      "23692/23692 [==============================] - 0s - loss: 20088053875459.7578     \n",
      "Epoch 153/200\n",
      "23692/23692 [==============================] - 0s - loss: 19957640357951.9688     \n",
      "Epoch 154/200\n",
      "23692/23692 [==============================] - 0s - loss: 19988817396323.3203     \n",
      "Epoch 155/200\n",
      "23692/23692 [==============================] - 0s - loss: 19807781388575.6836     \n",
      "Epoch 156/200\n",
      "23692/23692 [==============================] - 0s - loss: 19874890808641.3945     \n",
      "Epoch 157/200\n",
      "23692/23692 [==============================] - 0s - loss: 19923129264064.7227     \n",
      "Epoch 158/200\n",
      "23692/23692 [==============================] - 0s - loss: 19811475235602.9727     \n",
      "Epoch 159/200\n",
      "23692/23692 [==============================] - 0s - loss: 19972846238468.7969     \n",
      "Epoch 160/200\n",
      "23692/23692 [==============================] - 0s - loss: 19845650046449.0430     \n",
      "Epoch 161/200\n",
      "23692/23692 [==============================] - 0s - loss: 20176566613297.8359     \n",
      "Epoch 162/200\n",
      "23692/23692 [==============================] - 0s - loss: 19955695123113.5117     \n",
      "Epoch 163/200\n",
      "23692/23692 [==============================] - 0s - loss: 20023438871865.7891     \n",
      "Epoch 164/200\n",
      "23692/23692 [==============================] - 0s - loss: 19911558871027.2070     \n",
      "Epoch 165/200\n",
      "23692/23692 [==============================] - 0s - loss: 19805855583020.2148     \n",
      "Epoch 166/200\n",
      "23692/23692 [==============================] - 0s - loss: 19783812391394.6953     \n",
      "Epoch 167/200\n",
      "23692/23692 [==============================] - 0s - loss: 19607886969090.2930     \n",
      "Epoch 168/200\n",
      "23692/23692 [==============================] - 0s - loss: 19779236601221.1641     \n",
      "Epoch 169/200\n",
      "23692/23692 [==============================] - 0s - loss: 21144549626633.9844     \n",
      "Epoch 170/200\n",
      "23692/23692 [==============================] - 0s - loss: 19966094900058.5469     \n",
      "Epoch 171/200\n",
      "23692/23692 [==============================] - 0s - loss: 19788863976513.1797     \n",
      "Epoch 172/200\n",
      "23692/23692 [==============================] - 0s - loss: 19634176676250.0820     \n",
      "Epoch 173/200\n",
      "23692/23692 [==============================] - 0s - loss: 19893341373353.7305     \n",
      "Epoch 174/200\n",
      "23692/23692 [==============================] - 0s - loss: 19590831755862.1836     \n",
      "Epoch 175/200\n",
      "23692/23692 [==============================] - 0s - loss: 19640821596013.3945     \n",
      "Epoch 176/200\n",
      "23692/23692 [==============================] - 0s - loss: 19647536665121.6250     \n",
      "Epoch 177/200\n",
      "23692/23692 [==============================] - 0s - loss: 19712966470113.6602     \n",
      "Epoch 178/200\n",
      "23692/23692 [==============================] - 0s - loss: 19839838598861.9922     \n",
      "Epoch 179/200\n",
      "23692/23692 [==============================] - 0s - loss: 19636358761578.3242     \n",
      "Epoch 180/200\n",
      "23692/23692 [==============================] - 0s - loss: 19588555467275.1484     \n",
      "Epoch 181/200\n",
      "23692/23692 [==============================] - 0s - loss: 19491880686879.8555     \n",
      "Epoch 182/200\n",
      "23692/23692 [==============================] - 0s - loss: 19455557892307.2656     \n",
      "Epoch 183/200\n",
      "23692/23692 [==============================] - 0s - loss: 19356047494200.5352     \n",
      "Epoch 184/200\n",
      "23692/23692 [==============================] - 0s - loss: 19458928191853.4805     \n",
      "Epoch 185/200\n",
      "23692/23692 [==============================] - 0s - loss: 19230218470905.6914     \n",
      "Epoch 186/200\n",
      "23692/23692 [==============================] - 0s - loss: 19532166446979.5234     \n",
      "Epoch 187/200\n",
      "23692/23692 [==============================] - 0s - loss: 19402773161787.9453     \n",
      "Epoch 188/200\n",
      "23692/23692 [==============================] - 0s - loss: 19422543794547.3594     \n",
      "Epoch 189/200\n",
      "23692/23692 [==============================] - 0s - loss: 19677466721573.7344     \n",
      "Epoch 190/200\n",
      "23692/23692 [==============================] - 0s - loss: 19407054906678.6758     \n",
      "Epoch 191/200\n",
      "23692/23692 [==============================] - 0s - loss: 19307302504693.1523     \n",
      "Epoch 192/200\n",
      "23692/23692 [==============================] - 0s - loss: 19212978631512.8203     \n",
      "Epoch 193/200\n",
      "23692/23692 [==============================] - 0s - loss: 19489734663900.1680     \n",
      "Epoch 194/200\n",
      "23692/23692 [==============================] - 0s - loss: 19425078572962.9883     \n",
      "Epoch 195/200\n",
      "23692/23692 [==============================] - 0s - loss: 19300617360895.9141     \n",
      "Epoch 196/200\n",
      "23692/23692 [==============================] - 0s - loss: 19437167734238.3750     \n",
      "Epoch 197/200\n",
      "23692/23692 [==============================] - 0s - loss: 19235028399044.6992     \n",
      "Epoch 198/200\n",
      "23692/23692 [==============================] - 0s - loss: 19534709293703.2852     \n",
      "Epoch 199/200\n",
      "23692/23692 [==============================] - 0s - loss: 19015781971294.0938     \n",
      "Epoch 200/200\n",
      "23692/23692 [==============================] - 0s - loss: 19644631138256.9766     \n",
      "Epoch 1/10\n",
      "23692/23692 [==============================] - 0s - loss: 19008814067595.1289     \n",
      "Epoch 2/10\n",
      "23692/23692 [==============================] - 0s - loss: 18940983826193.7656     \n",
      "Epoch 3/10\n",
      "23692/23692 [==============================] - 0s - loss: 19199487151556.0977     \n",
      "Epoch 4/10\n",
      "23692/23692 [==============================] - 0s - loss: 19326661990147.9336     \n",
      "Epoch 5/10\n",
      "23692/23692 [==============================] - 0s - loss: 19303886055543.2891     \n",
      "Epoch 6/10\n",
      "23692/23692 [==============================] - 0s - loss: 18863139896212.6406     \n",
      "Epoch 7/10\n",
      "23692/23692 [==============================] - 0s - loss: 19393031804532.0938     \n",
      "Epoch 8/10\n",
      "23692/23692 [==============================] - 0s - loss: 18941624599161.4531     \n",
      "Epoch 9/10\n",
      "23692/23692 [==============================] - 0s - loss: 21048643541539.3555     \n",
      "Epoch 10/10\n",
      "23692/23692 [==============================] - 0s - loss: 19336126767072.1875     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c161b07d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN2.fit(X2,Y2, batch_size=batch_size2, epochs=200, verbose=1)\n",
    "#NN2.fit(X2,Y2, batch_size=batch_size2, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.58802778764\n"
     ]
    }
   ],
   "source": [
    "print r2_score(NN2.predict(X2),Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NN2.save('nn2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y1, X1, X1_test = map(np.array, [data1[\"price_doc\"], data1[v1], data_test1[v1]])\n",
    "#x_train, x_test = labels(x_train), labels(x_test||\n",
    "batch_size1=X1.shape[0]/50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN1 = larger_model(dim=X1.shape[1], reg=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN1.fit(X1,Y1, batch_size=batch_size1, epochs=200, verbose=0)\n",
    "NN1.fit(X1,Y1, batch_size=batch_size1, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NN1.save('nn1.h5')\n",
    "#NN1=load_model('nn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.32262013006e+25 -3.5981464011\n"
     ]
    }
   ],
   "source": [
    "print r2_score(NN1.predict(X1),Y1),r2_score(NN2.predict(X2),Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[data_test1[\"price_doc\"], data_test2[\"price_doc\"]] = [NN1.predict(X1_test), NN2.predict(X2_test)]\n",
    "out = data_test1[[\"id\",\"price_doc\"]].append(data_test2[[\"id\",\"price_doc\"]])\n",
    "out.to_csv(\"./nn2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_predict(data, data_test, ex, d, rs1=1, rs2=1, ts=0.1, md=5, sl=10, ne=100):\n",
    "    v=[x for x in list(data_test.columns.values) if x not in ex]\n",
    "    [values, features, features_test]  = [data[d], data[v], data_test[v]]\n",
    "    train, test, y_train, y_test = train_test_split(features, values, test_size=ts, random_state=rs1)\n",
    "    RFreg=RandomForestRegressor(random_state=rs2, max_depth=md, min_samples_leaf=sl, n_estimators=ne, oob_score=True)\n",
    "    RFreg.fit(train,y_train)\n",
    "    pred1 = RFreg.predict(test)\n",
    "    print r2_score(y_test, pred1)\n",
    "    pred_f=RFreg.predict(features_test)\n",
    "    return features_test[\"full_sq\"]*pred_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex=[\"id\",\"timestamp\",\"sub_area\", \"ID_metro\", \"ID_railroad_station_walk\", \"ID_railroad_station_avto\", \n",
    "    \"ID_big_road1\", \"ID_big_road2\", \"ID_railroad_terminal\", \"ID_bus_terminal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "def my_hist(data, d):\n",
    "    x=data[d].as_matrix()\n",
    "    bins = np.arange(0,3e5,1e4)\n",
    "    plt.hist(x, facecolor='green', alpha=0.75, bins=bins)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEECAYAAADpigmnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK5SzSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f702a08afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = \"pr_RUB_SQM\"\n",
    "my_hist(data1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEECAYAAADpigmnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f702a08a190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_hist(data2,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505425669374\n",
      "-0.199517942226\n"
     ]
    }
   ],
   "source": [
    "[data_test1[\"price_doc\"], data_test2[\"price_doc\"]] = [fit_predict(data1, data_test1, ex, d, rs1=3, sl=5),\n",
    "                                                      fit_predict(data2, data_test2, ex, d, rs1=5, sl=10)]\n",
    "out = data_test1[[\"id\",\"price_doc\"]].append(data_test2[[\"id\",\"price_doc\"]])\n",
    "out.to_csv(\"./result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnApplier(object):\n",
    "    def __init__(self, column_stages):\n",
    "        self._column_stages = column_stages\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i, k in self._column_stages.items():\n",
    "            k.fit(X[:, i])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for i, k in self._column_stages.items():\n",
    "            X[:, i] = k.transform(X[:, i])\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
